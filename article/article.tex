\documentclass{article}

\usepackage{mystyle}
\usepackage{myvars}



%-----------------------------

\begin{document}

	\maketitle % Insert title

	\thispagestyle{fancy} % All pages have headers and footers


%-----------------------------
%	ABSTRACT
%-----------------------------

	\begin{abstract}
		\noindent En este documento se realizarán experimentos sobre 3 conjuntos de datos utilizados para entrenar y verificar la tasa de error obtenida mediante distintas metodologías. Los algoritmos utilizados se basan en aprendizaje supervisado para la generación de árboles de decisión (\emph{J48}) y conjuntos de reglas(\emph{JRIP}) aplicado a tareas de clasificación.
	\end{abstract}

%-----------------------------
%	TEXT
%-----------------------------


	\section{Introducción}
	\label{sec:introducción}

		\paragraph{}
		El motivo principal por el cual se realiza este conjunto de experimentos es la comparación de las distintas tasas de error mediante cada una de las técnicas, tratando de apreciar el sesgo que producen cada una de ellas, así como la variación que producen. Las técnicas que utilizadas han sido:\emph{Holdout $\tfrac{2}{3}/\tfrac{1}{3}$}, \emph{3 Repeticiones de Holdout $\tfrac{2}{3}/\tfrac{1}{3}$}, \emph{Validación Cruzada de 10 capas} y \emph{3 Repeticiones de Validación Cruzada de 10 capas}. Dichas metodologías experimentales se describirán en cada una de sus correspondientes secciones. A continuación se describen brevemente los algoritmos y conjuntos de datos utilizados para las labores experimentales.

		\paragraph{}
		Para la realización de los experimentos se ha utilizado la biblioteca \textbf{Weka}\cite{tool:weka}, que permite la realización de distintas tareas de entrenamiento así como verificación relacionadas con la \emph{minería de datos} y los \emph{algoritmos de aprendizaje automático} de manera sencilla.

		\subsection{Algoritmos}

			\paragraph{}
			Los algoritmos utilizados para las tareas de aprendizaje pertenecen a la categoría de \emph{Aprendizaje Inductivo Basado en el Error}. Ambos algoritmos se basan en \emph{Aprendizaje Supervisado}, es decir, en la fase de entrenamiento utilizan el valor de la clase de destino como medida del error, el cual tratan de reducir al máximo. Mediante dicha estrategia tratan de conseguir clasificar correctamente las instancias futuras.

			\begin{itemize}

				\item \textbf{J48}: Es la implementación en Java de \emph{C4.5}, un método de generación de árboles de decisión basado en la \emph{Teoría de la Información}. En cada iteración trata de maximizar la ganancia de información producida tras cada partición con respecto de la clase de destino. Además, proporciona otras mejoras como \emph{poda de ramas} para evitar el sobreajuste, el uso de \emph{valores continuos} o el tratamiento de \emph{valores desconocidos}.


				\item \textbf{JRIP}: Es la implementación en Java de \emph{RIPPER}, un método de aprendizaje supervisado basado en reglas cuyas siglas significan \say{\emph{Repeated Incremental Pruning to Produce Error Reduction}}, lo que puede entenderse como la eliminación de reglas que se cumplen con pocas instancias para reducir el sobreajuste producido en la fase de aprendizaje, que genera todo el conjunto de reglas posibles a partir de una determinada heurística.

			\end{itemize}

		\subsection{Conjuntos de Datos}

			\paragraph{}
			Se han utilizado \textbf{3} conjuntos de datos en los experimentos realizados. Estos se describen brevemente a continuación:

			\begin{itemize}

				\item \textbf{Labor}\cite{dataset:labor}: Está formado por \emph{57 instancias} formadas por \emph{16 atributos} de los cuales, 8 de ellos son de tipo numérico mientras que el resto son de carácter nominal. La clase de destino puede tomar \emph{2 valores} distintos. El conjunto de datos se corresponde con resultados de negociaciones industriales en Canadá.

				\item \textbf{Soybean}\cite{dataset:soybean}: Está formado por \emph{683 instancias} formadas por \emph{35 atributos}, todos ellos de carácter nominal. La clase de destino puede tomar \emph{19 valores} distintos. El conjunto de datos se corresponde con instancias referidas a atributos de plantas y la clase de destino representa el tipo de planta.

				\item \textbf{Vote}\cite{dataset:vote}: Está formado por \emph{435 instancias} formadas por \emph{16 atributos}, todos ellos de carácter nominal. La clase de destino puede tomar \emph{2 valores} distintos. El conjunto de datos se refiere a resultados de encuestas a ciudadanos estadounidenses para tratar de predecir si votarán al partido demócrata o republicano.

			\end{itemize}

		\paragraph{}
		En las siguientes secciones se describen los experimentos realizados así como los resultados obtenidos en cada caso junto con una discusión acerca de los mismos. Algo a destacar es el uso de distintas semillas para la tarea de particionamiento, las cuales se han indicado en las tablas de resultados según corresponda.

	\section{Realizar un experimento aplicando Holdout $\tfrac{2}{3}/\tfrac{1}{3}$}
	\label{sec:e1}

		\paragraph{}
		El método de \emph{Holdout} consiste en el particionamiento del conjunto global de datos en 2 subconjuntos. Dicho método de experimentación requiere como entrada el porcentaje de datos que se utilizará para la tarea de entrenamiento, del cual se deriva el que se utilizará para test. En este caso se ha decidido utilizar $\tfrac{2}{3}$ del conjunto de datos para entrenamiento y $\tfrac{1}{3}$ para test. El método de selección que utiliza \emph{Holdout} para seleccionar las instancias que formarán cada conjunto es la \emph{selección aleatoria sin reemplazamiento}.


		\paragraph{}
		Los resultados obtenidos tras realizar el experimento descrito en el párrafo anterior se muestran en la tabla \ref{table:holdout-1-results}. En el caso del conjunto de datos \emph{Labor}, ambos algoritmos obtienen la misma tasa de error. Para los conjuntos de datos \emph{Soybean} y \emph{Vote} los resultados también son muy similares, por lo que no podemos decir a partir de estos resultados los algoritmos sean significativamente diferentes.

		\begin{table}[h]
			\centering
			\begin{tabular}{ | c | c | c | }
				\hline
				\multicolumn{3}{ | c | }{Holdout $2/3,1/3$} \\ \hline
				\multirow{2}{*}{Datos}		&\multirow{2}{*}{Algoritmo}	 	& Tasa de Error 		\\ \cline{3-3}
				 													&  														& $\text{Semilla}_1$\\ \hline
				\multirow{2}{*}{Labor} 		& J48 												& $10.5263\%$ 				\\ \cline{2-3}
																	& JRIP												&	$10.5263\%$					\\ \hline
				\multirow{2}{*}{Soybean} 	& J48 												& $9.4828\%$ 					\\ \cline{2-3}
																	& JRIP												&	$8.6207\%$					\\ \hline
				\multirow{2}{*}{Vote} 		& J48 												& $2.7027\%$ 					\\ \cline{2-3}
																	& JRIP												&	$3.3784\%$					\\
				\hline
			\end{tabular}
			\caption{Tasas de Error mediante la metodología experimental \emph{Holdout $2/3,1/3$}}
			\label{table:holdout-1-results}
		\end{table}


	\section{Realizar tres experimentos adicionales aplicando Holdout $\tfrac{2}{3}/\tfrac{1}{3}$, anotando la tasa de error de cada experimento}
	\label{sec:e2}

		\paragraph{}
		El método de \emph{Holdout repetido} consiste en realizar las mismas tareas que el descrito anteriormente, pero en este caso realiza la misma tarea durante un determinado número de veces. La razón de ello es tratar de minimizar la varianza de la tasa de error promediando los resultados de cada una de las repeticiones. En este caso se ha decidido realizar \emph{3 repeticiones} variando la semilla utilizada para cada uno de los experimentos de \emph{Holdout}. El tamaño de las particiones, al igual que en el caso anterior, ha sido de $\tfrac{2}{3}$ para entrenamiento y $\tfrac{1}{3}$ para test.

		\paragraph{}
		En este caso, los resultados se muestran en la tabla \ref{table:holdout-3-results}. Debido a la repetición del experimento, en este caso se pueden ver variaciones en las tasas de error respecto de la semilla escogida, algo que se comentará en la siguiente sección.

		\begin{table}[h]
			\centering
			\begin{tabular}{ | c | c | c | c | c | }
				\hline
				\multicolumn{5}{ | c | }{Holdout $2/3,1/3$ Repetido} \\ \hline
				\multirow{2}{*}{Datos}		&\multirow{2}{*}{Algoritmo}	 	& \multicolumn{3}{ c |}{Tasa de Error} \\ \cline{3-5}
				 													&  														& $\text{Semilla}_2$	& $\text{Semilla}_3$	& $\text{Semilla}_4$ \\ \hline
				\multirow{2}{*}{Labor} 		& J48 												& $15.7895\%$ & $31.5789\%$ & $10.5263\%$ \\ \cline{2-5}
																	& JRIP												&	$15.7895\%$ & $21.0526\%$ & $10.5263\%$ \\ \hline
				\multirow{2}{*}{Soybean} 	& J48 												& $11.2069\%$ & $10.7759\%$ & $13.7931\%$ \\ \cline{2-5}
																	& JRIP												&	$7.7586\%$ & $11.6379\%$ & $7.3276\%$	\\ \hline
				\multirow{2}{*}{Vote} 		& J48 												& $8.1081\%$ & $5.4054\%$ & $6.0811\%$	\\ \cline{2-5}
																	& JRIP												&	$5.4054\%$ & $4.7297\%$ & $4.7297\%$	\\
				\hline
			\end{tabular}
			\caption{Tasas de Error mediante la metodología experimental \emph{Holdout $2/3,1/3$ Repetido}}
			\label{table:holdout-3-results}
		\end{table}

	\section{Sobre los resultados calculados en la sección \ref{sec:e2} determinarla tasa de error, la varianza y el intervalo de confianza del $95\%$}
	\label{sec:e3}

		\paragraph{}
		En esta sección se realizan las tareas de promediación así como del cálculo de la desviación típica y los intervalos de confianza correspondientes a los resultados de la sección \ref{sec:e2}.

		\paragraph{}
		En el caso del cálculo de la esperanza, se ha seguido la definición de la ecuación \eqref{eq:holdout-E}, la cual se define como la media aritmética del error.

		\begin{equation}
		\label{eq:holdout-E}
				e(h) = \frac{\sum_{i=1}^k e_i(h)}{k}
		\end{equation}

		\paragraph{}
		En el caso de la desviación típica, se ha utilizado la ecuación \eqref{eq:holdout-V-root}, que se corresponde con la definición de desviación típica muestral, pero utilizando la cuasi-varianza, la cual reduce el sesgo que se podría producir respecto del valor poblacional.

		\begin{equation}
		\label{eq:holdout-V-root}
				S_e(h) = \sqrt{\frac{\sum_{i=1}^k (e_i(h)-e(h))^2}{k-1}}
		\end{equation}


		\paragraph{}
		En el caso de los intervalos de confianza, se ha utilizado la ecuación \eqref{eq:holdout-Bounds}, la cual se apoya en la distribución \emph{T de Student}, así como la esperanza \eqref{eq:holdout-E} como punto de equilibrio y la desviación típica \eqref{eq:holdout-V-root} calculadas previamente.

		\begin{equation}
		\label{eq:holdout-Bounds}
			[e(h)-t_{N, k-1} * \frac{S_e(h)}{\sqrt{k}},e(h)+t_{N, k-1} * \frac{S_e(h)}{\sqrt{k}}]
		\end{equation}

		\paragraph{}
		Los resultados de aplicar las operaciones descritas sobre los resultados de la sección anterior se muestran en la tabla \ref{table:holdout-3-results-global}. Tal y como se puede apreciar, el algoritmo \emph{J48} tiene una tasa de error mayor que \emph{JRIP} en promedio para los experimentos realizados.

		\begin{table}[h]
			\centering
			\begin{tabular}{ | c | c | c | c | c | }
				\hline
				\multicolumn{5}{ | c | }{Holdout $2/3,1/3$: Global } \\ \hline
				Datos											& Algoritmo	 									& Tasa de Error	& Desviación Estandar	& Intervalos \\ \hline
				\multirow{2}{*}{Labor} 		& J48 												& $19.2982\%$ 		& $10.9561\%$ 					& $[0.8277\%,37.7686\%]$ \\ \cline{2-5}
																	& JRIP												&	$15.7894\%$ 		& $5.2631\%$ 					& $[6.9165\%,24.6622\%]$ \\ \hline
				\multirow{2}{*}{Soybean} 	& J48 												& $11.9253\%$ 		& $1.6318\%$ 					& $[9.1743\%,14.6762\%]$ \\ \cline{2-5}
																	& JRIP												&	$8.9080\%$ 		& $2.3739\%$ 					& $[4.9059\%,12.9100\%]$	\\ \hline
				\multirow{2}{*}{Vote} 		& J48 												& $6.5315\%$ 		& $1.4065\%$ 					& $[4.1603\%,8.9026\%]$ \\ \cline{2-5}
																	& JRIP												&	$4.9549\%$ 		& $0.3901\%$ 					& $[4.2972\%,5.6125\%]$	\\
				\hline
			\end{tabular}
			\caption{Tasas de Error Global mediante la metodología experimental \emph{Holdout $2/3,1/3$ Repetido}}
			\label{table:holdout-3-results-global}
		\end{table}

	\section{Realizar un experimento de validación cruzada de $10$ particiones, calculando la tasa de error}
	\label{sec:e4}

		\paragraph{}
		El método de particionamiento mediante \emph{Validación Cruzada} trata de mejorar los resultados obtenidos mediante \emph{Holdout} respecto del grado de precisión de la tasa de error. Para ello divide el conjunto de datos en $k$ particiones de igual tamaño para después realizar $k$ experimentos utilizando cada vez una de las particiones como conjunto de test y el resto como conjunto de entrenamiento. Posteriormente se promedian los resultados de cada uno de los experimentos para obtener el resultado final. Con esto se consigue un menor sesgo a costa de un mayor coste computacional para la estimación. En este caso se ha escogido $k = 10$ particiones para el experimento de \emph{Validación Cruzada}.

		\paragraph{}
		Los resultados obtenidos tras realizar el experimento del párrafo anterior se muestran en la tabla \ref{table:cross-validation-1-results}. Como vemos, tienen una tendencia similar a los obtenidos en la sección \ref{sec:e1}. Posteriormente (en última sección) se comentarán las variaciones en los resultados dependientes de la metodología experimental utilzada.

		\begin{table}[h]
			\centering
			\begin{tabular}{ | c | c | c | }
				\hline
				\multicolumn{3}{ | c | }{Validación Cruzada de 10 capas} \\ \hline
				\multirow{2}{*}{Datos}		&\multirow{2}{*}{Algoritmo}	 	& Tasa de Error 		\\ \cline{3-3}
																	&  														& $\text{Semilla}_1$\\ \hline
				\multirow{2}{*}{Labor} 		& J48 												& $26.3158\%$ 				\\ \cline{2-3}
																	& JRIP												&	$22.8070\%$					\\ \hline
				\multirow{2}{*}{Soybean} 	& J48 												& $8.4919\%$ 					\\ \cline{2-3}
																	& JRIP												&	$7.7599\%$					\\ \hline
				\multirow{2}{*}{Vote} 		& J48 												& $3.6782\%$ 					\\ \cline{2-3}
																	& JRIP												&	$4.5977\%$					\\
				\hline
			\end{tabular}
			\caption{Tasas de Error mediante la metodología experimental \emph{Validación Cruzada de 10 capas}}
			\label{table:cross-validation-1-results}
		\end{table}

	\section{Realizar tres experimentos de validación cruzada de $10$ particiones, anotando la tasa de error}
	\label{sec:e5}

		\paragraph{}
		La \emph{Validación Cruzada Repetida} consiste, al igual que el \emph{Holdout repetido}, en realizar varios experimentos con distintas semillas para después promediar los resultados tal y como se hará en la siguiente sección.

		\paragraph{}
		Los resultados obtenidos tras la realización del experimento de \emph{Validación Cruzada Repetida} variando la semilla de particionamiento se muestran en la tabla \ref{table:cross-validation-3-results}. Como vemos, en este caso la desviación típica entre los resultados es mucho menor que en el caso de \emph{Holdout Repetido} de la sección \ref{sec:e3}.

		\begin{table}[h]
			\centering
			\begin{tabular}{ | c | c | c | c | c | }
				\hline
				\multicolumn{5}{ | c | }{Validación Cruzada de 10 capas Repetida} \\ \hline
				\multirow{2}{*}{Datos}		&\multirow{2}{*}{Algoritmo}	& \multicolumn{3}{ c |}{Tasa de Error} \\ \cline{3-5}
				 													&  													& $\text{Semilla}_2$	& $\text{Semilla}_3$	& $\text{Semilla}_4$ \\ \hline
				\multirow{2}{*}{Labor} 		& J48 											& $26.3158\%$ & $26.3158\%$ & $24.5614\%$ \\ \cline{2-5}
																	& JRIP											&	$14.0351\%$ & $15.7895\%$ & $15.7895\%$ \\ \hline
				\multirow{2}{*}{Soybean} 	& J48 											& $9.8097\%$ & $9.0776\%$ & $7.9063\%$ 	\\ \cline{2-5}
																	& JRIP											&	$8.6384\%$ & $6.8814\%$ & $8.1991\%$	\\ \hline
				\multirow{2}{*}{Vote} 		& J48 											& $3.2184\%$ & $3.6782\%$ & $3.4483\%$ 	\\ \cline{2-5}
																	& JRIP											&	$4.3678\%$ & $4.1379\%$ & $3.908\%$		\\
				\hline
			\end{tabular}
			\caption{Tasas de Error mediante la metodología experimental \emph{Validación Cruzada de 10 capas Repetida}}
			\label{table:cross-validation-3-results}
		\end{table}


	\section{Sobre los resultados calculados en la sección \ref{sec:e5} determinar la tasa de error}
	\label{sec:e6}

		\paragraph{}
		La ecuación utilizada para el cálculo de la experanza, en este caso ha sido \eqref{eq:cross-validation-E}. Puesto que los resultados que se muestran en la tabla de resultado ya han sido promediados respecto de cada una de sus particiones, no es dificil comprobar que la esperanza global puede obtener mediante una simple media aritmética de los mismos, tal y como sucede en el caso del \emph{Holdout Repetido} y la ecuación \eqref{eq:holdout-E}.

		\begin{equation}
		\label{eq:cross-validation-E}
			e(h) = \frac{\sum_{i=1}^{R*k}e_i(h)}{R*k}
		\end{equation}

		\paragraph{}
		En la tabla \ref{table:cross-validation-3-results-global} se muestran los resultados de promediar las tasas de error obtenidas en la sección anterior. Tal y como se ha comentado anteriormente, mediante la técnica de repetición el sesgo producido al realizar la metodología experimental es mucho menor en este caso con respecto a la \emph{Validación Cruzada} de una única repetición.

		\begin{table}[h]
			\centering
			\begin{tabular}{ | c | c | c | }
				\hline
				\multicolumn{3}{ | c | }{Validación Cruzada Repetida: Global} \\ \hline
				Datos											& Algoritmo	& Tasa de Error \\ \hline
				\multirow{2}{*}{Labor} 		& J48 			& $25.731\%$ \\ \cline{2-3}
																	& JRIP			&	$15.2047\%$	\\ \hline
				\multirow{2}{*}{Soybean} 	& J48 			& $8.9312\%$ \\ \cline{2-3}
																	& JRIP			&	$7.9063\%$	\\ \hline
				\multirow{2}{*}{Vote} 		& J48 			& $3.4483\%$ \\ \cline{2-3}
																	& JRIP			&	$4.1379\%$	\\
				\hline
			\end{tabular}
			\caption{Tasas de Error Global mediante la metodología experimental \emph{Validación Cruzada de 10 capas Repetida}}
			\label{table:cross-validation-3-results-global}
		\end{table}

	\section{Conclusiones}
	\label{sec:conclusions}

		\paragraph{}
		A continuación se muestran los resultados referidos a las tasas de error obtenidas a través de cada una de las metodologías experimentales, agrupadas por conjuntos de datos. Además, se describe un breve comentario acerca de cada uno de los resultados.

		\subsection{Labor}
		\label{sec:conclusions-labor}

			\paragraph{}
			En la tabla \ref{table:data-set-labor-results} se muestran los resultado de todos los experimentos realizados sobre el conjunto de datos \emph{Labor}. En este caso los distintos experimentos proporcionan resultados muy variables según la metodología seguida. Sin embargo, en promedio, el clasificador generado a partir de \emph{JRIP} presenta una menor tasa de error en 3 de los 4 experimentos realizados.

			\begin{table}[h]
				\centering
				\begin{tabular}{ | c || c | c | c | c |}
				\hline
				\multicolumn{5}{ | c | }{Conjunto de Datos: Labor} \\ \hline
				Algoritmo	&	Holdout 		& Holdout Repetido 	& Validación Cruzada 	& Validación Cruzada Repetida \\ \hline \hline
				J48				&	$10.5263\%$	&	$19.2982\%$				&	$26.3158\%$					&	$25.731\%$										\\ \hline
				JRIP			& $10.5263\%$	&	$15.7894\%$				&	$22.8070\%$					&	$15.2047\%$									\\
				\hline
				\end{tabular}
				\caption{Resultados de la distintas Metodologías Experimentales para el conjunto de datos \emph{Labor}}
				\label{table:data-set-labor-results}
			\end{table}

		\subsection{Soybean}
		\label{sec:conclusions-soybean}

			\paragraph{}
			En la tabla \ref{table:data-set-soybean-results} se muestran los resultado de todos los experimentos realizados sobre el conjunto de datos \emph{Soybean}. En este caso los resultados de los experimentos también otorgan una menor tasa de error en el caso del algoritmo \emph{JRIP} para la clasificación de instancias desconocidas. Podemos interpretar que el algoritmo \emph{JRIP} se comportará mejor sobre datos semejantes, pero es algo que hay que tratar con cautela, puesto que las diferencias entre tasas de error son muy reducidas.

			\begin{table}[h]
				\centering
				\begin{tabular}{ | c || c | c | c | c |}
				\hline
				\multicolumn{5}{ | c | }{Conjunto de Datos: Soybean} \\ \hline
				Algoritmo	&	Holdout 		& Holdout Repetido 	& Validación Cruzada 	& Validación Cruzada Repetida \\ \hline \hline
				J48				&	$9.4828\%$	&	$11.9253\%$				&	$8.4919\%$					&	$8.9312\%$									\\ \hline
				JRIP			& $8.6207\%$	&	$8.908\%$					&	$7.7599\%$					&	$7.9063\%$									\\
				\hline
				\end{tabular}
				\caption{Resultados de la distintas Metodologías Experimentales para el conjunto de datos \emph{Soybean}}
				\label{table:data-set-soybean-results}
			\end{table}

		\subsection{Vote}
		\label{sec:conclusions-vote}

			\paragraph{}
			En la tabla \ref{table:data-set-vote-results} se muestran los resultado de todos los experimentos realizados sobre el conjunto de datos \emph{Labor}. Tras examinar los resultados de los experimentos realizados, y sin tener en cuenta técnicas estadísticas para su afirmación, de que el algoritmos \emph{J48} se comporta mejor sobre el conjunto de datos. Sin embargo, al igual que en el caso del conjunto de datos \emph{Soybean}, estas diferencias en la tasa de error son demasiado reducidas como para poder afirmarlo con alto grado de confianza.

			\begin{table}[h]
				\centering
				\begin{tabular}{ | c || c | c | c | c |}
				\hline
				\multicolumn{5}{ | c | }{Conjunto de Datos: Vote} \\ \hline
				Algoritmo	&	Holdout 		& Holdout Repetido 	& Validación Cruzada 	& Validación Cruzada Repetida \\ \hline \hline
				J48				&	$2.7027\%$	&	$6.5315\%$				&	$3.6782\%$ 					&	$3.4483\%$									\\ \hline
				JRIP			&	$3.3784\%$	&	$4.9549\%$				&	$4.5977\%$					&	$4.1379\%$									\\
				\hline
				\end{tabular}
				\caption{Resultados de la distintas Metodologías Experimentales para el conjunto de datos \emph{Vote}}
				\label{table:data-set-vote-results}
			\end{table}

%-----------------------------
%	Bibliographic references
%-----------------------------
	\nocite{garciparedes:machine-learning-hypothesis-evaluation}
	\nocite{subject:taa}
	\nocite{tool:weka}
  \bibliographystyle{alpha}
  \bibliography{bib/misc}

\end{document}
